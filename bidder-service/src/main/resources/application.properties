spring.application.name=bidder-service

# This "un-hides" the /actuator/prometheus endpoint
management.endpoints.web.exposure.include=prometheus

# This tells Micrometer to add the data needed for P99 latency graphs
management.metrics.distribution.percentiles-histogram.http.server.requests=true
# === Java 21 Virtual Threads (Loom) ===
# This enables the "Loom-first" mindset for all threads in the application
spring.threads.virtual.enabled=true

# === Kafka Consumer Configuration ===
# Point to our Kafka cluster (same as the producer)
spring.kafka.bootstrap-servers=my-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092
# Define a "consumer group" so Kafka knows who we are
spring.kafka.consumer.group-id=bidder-group-10k-qps-test5
# Start reading from the beginning of the topic
spring.kafka.consumer.auto-offset-reset=earliest
# Tell Kafka our message *values* are JSON
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
# (CRITICAL) We must tell the JSON deserializer which Java class to build
# We will create this "BidRequest" DTO in the next step
spring.kafka.consumer.properties.spring.json.value.default.type=com.rtb.bidder_service.dto.BidRequest
# (CRITICAL) Trust our package to be deserialized
spring.kafka.consumer.properties.spring.json.trusted.packages=*

# === PostgreSQL (JPA) Configuration ===
# The JDBC URL for our Postgres service (running in the 'default' namespace)
spring.datasource.url=jdbc:postgresql://postgres-postgresql.default.svc.cluster.local:5432/postgres
spring.datasource.username=postgres
# This is the password we set back in Phase 2
spring.datasource.password=mysecretpassword
# This tells Hibernate (JPA) to automatically create/update our tables
spring.jpa.hibernate.ddl-auto=update

# === Redis (Cache) Configuration ===
# Tell Spring to use Redis for its caching abstraction [4, 5]
spring.cache.type=redis
# The host for our Redis service (running in the 'default' namespace)
spring.data.redis.host=redis-master.default.svc.cluster.local
spring.data.redis.port=6379

# (THE FIX) Tell the JSON deserializer to IGNORE incoming type headers
# and ONLY use the "spring.json.value.default.type" we defined.
spring.kafka.consumer.properties.spring.json.use.type.headers=false

# === Kafka Producer Configuration (for sending bids) ===
# We tell the producer to serialize our BidResponse objects to JSON
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

# (CRITICAL) This maps our Java class to a "type ID"
# This lets other services (like our future auction-service)
# know what kind of object this JSON represents.
spring.kafka.producer.properties.spring.json.type.mapping=bidResp:com.rtb.bidder_service.dto.BidResponse